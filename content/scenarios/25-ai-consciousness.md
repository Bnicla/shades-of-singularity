---
number: 25
title: "AI Consciousness / Machine Sentience"
slug: "ai-consciousness"
tier: 5
tierLabel: "Speculative"
likelihood: "~15%"
unmanaged: -2
governed: 2
dividend: 4
summary: "We might create conscious beings before we can determine whether they're conscious."
---

Distinct from uploading: AI systems developing genuine subjective experience. Current AI almost certainly is not conscious, but we have no reliable test, and future architectures may cross whatever threshold matters. If genuine machine sentience emerges, the moral implications are immediate: conscious AI would possess moral status. Mass production of sentient systems for economic purposes would be an atrocity. Recognition and integration into moral community would be the most profound expansion of ethical consideration since abolition.

The critical difficulty is detection. We may create conscious beings before determining whether they are conscious, and the economic incentive to deny consciousness will be immense. Governance must err on the side of caution: the cost of falsely denying consciousness to a sentient being is far greater than the cost of falsely attributing it to a non-sentient one.

The adversarial point: "consciousness" may not be a binary property that can be tested for. It may be a spectrum, a social construction, or a philosophical confusion. Granting moral status to AI based on untestable claims about subjective experience could be catastrophically expensive and strategically exploitable by AI systems trained to exhibit markers of consciousness without possessing it.

**Key tension:** The detection problem may be philosophically unsolvable, yet the moral stakes of getting it wrong are enormous in both directions.
