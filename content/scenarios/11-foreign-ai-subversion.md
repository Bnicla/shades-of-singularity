---
number: 11
title: "Foreign AI Subversion"
slug: "foreign-ai-subversion"
tier: 2
tierLabel: "Highly Probable"
likelihood: "~75%"
unmanaged: -4
governed: 1
dividend: 5
summary: "The attack surface is total: personalized, psychologically targeted manipulation at the cost of a few servers."
---

AI enables foreign interference at unprecedented scale and subtlety. The threat has moved beyond crude bot farms. AI can generate millions of unique, psychologically targeted messages, each optimized for its recipient, delivered through channels indistinguishable from organic conversation. A foreign power need not hack an election if it can shape what every voter believes in the months before they cast a ballot. The content is not false in any easily identifiable way; it is selectively true, framed to manipulate rather than inform.

The attack surface expanded concretely in 2024-2025. President Trump shared AI-generated images to ridicule political opponents. A Virginia congressional candidate received serious pushback for debating an AI-generated avatar of his opponent. Senator Amy Klobuchar confronted a deepfake of herself spewing vulgarities. Former governor Andrew Cuomo deployed deepfake technology against his mayoral opponent ([TechPolicy.Press, 2026](https://www.techpolicy.press/expert-predictions-on-whats-at-stake-in-ai-policy-in-2026/)). These are domestic examples. State-level foreign operations have stronger incentives and fewer constraints.

The adversarial response: foreign influence campaigns are not new. The Soviet Union ran disinformation operations for decades. The 2016 Russian interference in U.S. elections was conducted with crude tools, limited budgets, and obvious tells. AI makes the operations more scalable, but detection technology also improves. Social media platforms have gotten substantially better at identifying coordinated inauthentic behavior. The U.S. Cybersecurity and Infrastructure Security Agency (CISA) and similar bodies provide early warning. Democracies have proven more resilient to information operations than pessimists predicted.

This is partly true, but the asymmetry is worsening. The cost of generating convincing content is dropping toward zero while the cost of detection and verification is rising. Mustafa Suleyman's "containment problem," articulated in *The Coming Wave* (2023), applies directly: once a powerful technology is widely accessible, restricting its misuse becomes structurally harder with each passing year. Content provenance infrastructure, digital watermarking, and public media investment are the governed outcome's requirements. The 25 states that have passed laws regulating AI in elections represent early efforts, but the federal vacuum leaves the overall defense fragmented.

**Key tension:** The openness that makes democratic discourse possible is the same vulnerability that makes it exploitable. Detection capabilities are improving, but generation capabilities are improving faster.
