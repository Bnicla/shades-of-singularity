# The Blueprint

Five institutional mechanisms designed to claim the governance dividend.

---

## Blueprint 1: Public Ownership of AI Infrastructure
*Public equity stakes in frontier AI companies, with returns distributed as a consumer dividend. Alaska Permanent Fund as proof of concept, scaled 50-100x.*


Content coming soon.

---

## Blueprint 2: Market Access as the Enforcement Lever
*Condition access to the $18 trillion US consumer market on governance compliance: transparency, safety standards, public equity provisions, environmental standards, content provenance.*


Content coming soon.

---

## Blueprint 3: New Economic Metrics Deployed Urgently
*Provisioning rate and demand velocity: the instruments needed to see what GDP hides. You cannot govern what you cannot measure.*


Content coming soon.

---

## Blueprint 4: Content Provenance Infrastructure
*Cryptographic verification of authentic content, mandatory AI-content disclosure, watermarking standards. The epistemic commons that democracy requires.*


Content coming soon.

---

## Blueprint 5: Meaning Infrastructure at Civilizational Scale
*Publicly guaranteed work, massively expanded arts and sciences, and the Athenian model as conscious design goal. AI replaces the slave class, freeing citizens for learning, culture, and civic life.*


Content coming soon.

---


## Blueprint Working Notes (Raw Material)

# Blueprint Notes

*Governance responses and institutional design elements extracted from each scenario.*
*These are the raw materials for the Blueprint document.*

---

## Scenario #1: The Gradual Erosion of Human Labor Value

- This creates a self-reinforcing cycle. As AI absorbs cognitive tasks, the remaining positions attract more applicants competing for fewer openings, which drives wages down. Lower wages reduce consumer spending. Reduced spending contracts the economy, which pressures more firms to cut costs throug...
- The governed outcome here carries the collection's highest dividend (+6) because the same productivity gains that cause the damage also fund the solution. The solution will not come from companies. It cannot. Capitalism is designed to reward shareholders, and corporate leaders will maximize for p...
- The fundamental shift required is decoupling income from employment. The current economy distributes purchasing power primarily through wages. When AI performs the work, wages vanish. The result is what economists describe as a crisis of overproduction: supply is plentiful, demand collapses, beca...

## Scenario #2: The Concentration of AI Power

- The concentration of economic power translates directly into political power. The technology industry spent over [$250 million on federal lobbying in 2024](https://www.opensecrets.org/news/2025/02/federal-lobbying-set-new-record-in-2024/), deploying nearly [500 lobbyists across three Congresses, ...
- The most recent phase of concentration moves beyond infrastructure into the application layer itself. For years, software companies sold tools that humans used. Then AI startups built "GPT wrappers" that added intelligence to those tools. Now the frontier labs are absorbing both layers. In early ...
- The analogy to hereditary aristocracy is structural. When economic power translates directly into the ability to shape the rules governing that power, concentration becomes self-perpetuating. The "machine aristocracy" requires treating frontier AI compute as public infrastructure too consequentia...

## Scenario #3: The Surveillance Singularity

- Comprehensive surveillance was always limited by the cost of human attention. There were never enough watchers for all the watched. AI eliminates this bottleneck entirely. A single system can now monitor millions of faces, conversations, transactions, and movements simultaneously, at trivial marg...
- This is not only a Chinese phenomenon. The Carnegie Endowment's AI Global Surveillance Index found that Chinese tech companies supply AI surveillance technology to at least 63 countries, and over 70% of Huawei's "safe city" agreements involve nations rated "partly free" or "not free" by Freedom H...
- Democratic nations face their own version, less dramatic but equally pervasive. In the United States, 74% of employers now use online tracking tools, including real-time screen monitoring and web browsing logs, while 75% monitor physical workplaces through cameras, badge systems, and biometric ac...
- Even optimistic governance barely breaks even on this shade. The track record demands honesty. "Privacy by design" has been a stated principle since Ann Cavoukian coined the term in 1995. Three decades later, a 2022 European Commission study found that 97% of the most popular websites and apps us...
- The most instructive case may be WhatsApp. After the Snowden revelations made mass surveillance a public concern, WhatsApp partnered with Open Whisper Systems in late 2014 to deploy the Signal protocol, giving two billion users end-to-end encryption that Meta itself cannot break ([Wiley/Johansen ...

## Scenario #4: Information Collapse

- *Fabrication is now cheaper, faster, and more scalable than verification, and every institution that depends on evidence is built on the opposite assumption.*
- The deeper danger is that people will stop believing anything. For most of human history, the difficulty of fabrication functioned as an invisible guarantor of trust. Photographs were evidence because faking them required a darkroom and expertise. Video was definitive because no one could manufac...
- The governance response centers on content provenance. The Coalition for Content Provenance and Authenticity (C2PA), an alliance of Adobe, Microsoft, Intel, the BBC, and over 200 organizations, has developed Content Credentials: a cryptographic standard that functions as a nutrition label for dig...
- **Key tension:** Fabrication is cheap, fast, and default. Verification is expensive, slow, and opt-in. Every institution that depends on evidence, from courts to science to democracy, is built on an assumption of scarcity that no longer holds.

## Scenario #5: The Drowning of the Internet

- Open source software is the canary. Daniel Stenberg shut down curl's bug bounty program after AI-generated submissions drove valid vulnerability reports from 15% of submissions down to 5% ([LeadDev, 2026](https://leaddev.com/software-quality/open-source-has-a-big-ai-slop-problem)). Mitchell Hashi...
- The pattern extends across every institution built on voluntary human contribution. Wikipedia created WikiProject AI Cleanup and adopted a speedy deletion policy for AI-generated articles in August 2025 after editors reported being "flooded non-stop with horrendous drafts" containing fabricated c...
- The counterargument deserves weight. These systems have always faced gaming, spam, and bad-faith actors. Wikipedia survived vandalism, edit wars, and paid editing campaigns. Open source survived corporate co-optation and license wars. Amazon reviews survived incentivized review schemes. Each time...
- The counterresponse: previous attacks were human-scale. A spam army of 10,000 people is expensive, slow, and detectable. An AI army of 10,000 agents costs almost nothing, runs continuously, and improves over time. The defenses themselves increasingly require AI, creating a recursive dependence wh...

## Scenario #6: The Cognitive Atrophy Trap

- The consequences are professional, democratic, and self-reinforcing. In the ACCEPT trial, endoscopists who used AI-assisted polyp detection for six months saw their adenoma detection rate drop from 28% to 22% when AI was removed: six months of assistance produced a 20% decline in unaided diagnost...
- The democratic consequences connect directly to Shade #4. Cognitive atrophy is what makes information collapse lethal. A population with strong analytical skills can survive a polluted information environment; a population without them cannot. The combination of scalable fabrication and degraded ...
- The governance response is education reform. Finland's national media literacy curriculum, integrating critical thinking about information sources from primary school onward, has been cited as a model ([Frontiers in Communication, 2025](https://public-pages-files-2025.frontiersin.org/journals/com...

## Scenario #7: The Geopolitical AI Arms Race

- The superpower competition sits behind this battlefield. Leopold Aschenbrenner's ["Situational Awareness"](https://situational-awareness.ai/) (June 2024), written by a former OpenAI researcher with insider access to capability trajectories, argues that AGI arriving by 2027 would trigger the most ...
- The honest counterargument is that arms control has worked before. The Nuclear Non-Proliferation Treaty, the Chemical Weapons Convention, and the various strategic arms limitation agreements all constrained powerful technologies despite intense geopolitical competition. As former NSA Jake Sulliva...
- **Key tension:** Mutual restraint produces the best collective outcome, but each actor's dominant strategy is to escalate, and the verification mechanisms that made nuclear arms control possible do not obviously translate to AI.

## Scenario #8: Governance Obsolescence

- *The deliberation that makes democratic governance legitimate is the same quality that may make it fatally slow.*
- During the 118th Congress (2023-2024), lawmakers introduced over 150 bills concerning artificial intelligence. None passed into law ([Brennan Center, AI Legislation Tracker](https://www.brennancenter.org/our-work/research-reports/artificial-intelligence-legislation-tracker)). In 2025, more than 1...
- The European Union passed the AI Act in 2024 as the world's first comprehensive AI regulation. Before its high-risk provisions could take effect in August 2026, the European Commission proposed delaying them to late 2027 through a "Digital Omnibus" package, acknowledging that supporting standards...
- The counterargument deserves its full weight. Governance activity is surging. Stanford HAI's 2025 AI Index reports that legislative AI mentions across 75 countries grew more than ninefold since 2016. U.S. federal agencies introduced 59 AI-related regulations in 2024, more than double the prior ye...
- And democratic institutions already have models for governing at speed. Financial regulators adjust monetary policy in real time. The FDA grants emergency use authorizations that compress years of review into weeks. Securities regulation operates at the tempo of the markets it oversees. None of t...
- So the real diagnosis may be political failure rather than structural incompatibility. The tools exist. The institutional models exist. What does not exist is the political will to build an AI equivalent of the Fed or the FDA, in a country where the dominant AI power's administration views regula...

## Scenario #9: The Meaning Crisis

- The adversarial counterargument: humans have survived previous meaning crises. Industrialization, the decline of religion, the shift from agrarian to urban life all disrupted identity structures. People adapted. Retirement does not routinely produce mass despair. Retirees with sufficient resource...
- This is partly right. The governed outcome (+2) depends on building institutions that cultivate meaning: education systems emphasizing embodiment, relationship, moral judgment, and care; cultural frameworks valuing process over product; economic structures rewarding engagement rather than output....

## Scenario #10: The Ecological Reckoning

- The governed outcome (+3) reflects the potential for regulation to force the industry toward renewable energy, water efficiency, and algorithmic optimization while preserving AI's environmental benefits. The unmanaged outcome (-3) reflects the alternative: exponential growth in energy demand, pre...

## Scenario #11: Foreign AI Subversion

- The attack surface expanded concretely in 2024-2025. President Trump shared AI-generated images to ridicule political opponents. A Virginia congressional candidate received serious pushback for debating an AI-generated avatar of his opponent. Senator Amy Klobuchar confronted a deepfake of herself...
- This is partly true, but the asymmetry is worsening. The cost of generating convincing content is dropping toward zero while the cost of detection and verification is rising. Mustafa Suleyman's "containment problem," articulated in *The Coming Wave* (2023), applies directly: once a powerful techn...
- **Key tension:** The openness that makes democratic discourse possible is the same vulnerability that makes it exploitable. Detection capabilities are improving, but generation capabilities are improving faster.

## Scenario #12: The Synthetic Persons Economy

- The response: the change of degree may cross a threshold. When the majority of market signals originate from non-human actors, price discovery loses its informational justification. The response requires legal frameworks for non-human economic agents, "personhood verification" for consequential t...

## Scenario #13: Alignment Failure (Misaligned Superintelligence)

- Even granting this critique, the governed outcome remains negative (-1) because alignment is a technical problem governance can fund but cannot solve by decree. The 4-point dividend reflects the value of massive investment in safety research, international standards, and adversarial testing: buyi...

## Scenario #14: Digital Authoritarianism as Global Norm

- *Even democratic societies may drift toward algorithmic governance through convenience rather than tyranny.*
- China's AI-powered governance is an export product. Through the Digital Silk Road, Chinese surveillance infrastructure, social credit frameworks, and censorship tools are being adopted across Africa, Southeast Asia, and the Middle East. The attraction is pragmatic: AI surveillance is cheaper, mor...
- China's domestic regulatory speed, discussed in Shade 7, has a mirror image: Beijing implemented binding generative AI rules within months of ChatGPT's release partly because the CPC treats information control as a core governance function. The efficiency that enables rapid regulation also enable...
- The counterargument: the "authoritarian tech export" narrative is overstated. Many countries that purchase Chinese surveillance technology do so for pragmatic reasons (price, availability) without adopting China's governance model. India, the world's largest democracy, uses extensive biometric an...
- The governed outcome (+1) requires democratic nations to develop a compelling alternative: AI governance that preserves liberties while delivering comparable effectiveness. The structural constraint on power, rather than reliance on the virtue of those who wield it, is essential.
- **Key tension:** The efficiency of algorithmic governance is genuine. Democratic alternatives must be built, not assumed.

## Scenario #15: Permanent Underclass / Neo-Feudalism

- The counterargument: historical predictions of permanent stratification from new technology have consistently been wrong. The printing press, electricity, the internet, and mobile computing all initially concentrated advantages before diffusing broadly. AI tools are already cheap: a $20 subscript...
- This counterargument has real force on the tools side. It has less force on the capital side. If AI-driven productivity gains flow primarily to capital owners, cheap AI access does not prevent economic bifurcation. You can have a smartphone and still be structurally poor. The 6-point dividend ref...
- **Key tension:** The owners of AI gain more than money; they gain access to fundamentally different levels of intelligence and capability. Whether that advantage diffuses or entrenches depends on policy choices being made now.

## Scenario #17: The Fragmentation of Reality

- The counterargument: people have always lived in different information environments. In the 19th century, a farmer in Kansas and a banker in Manhattan shared almost no informational common ground. Mass media created shared reality; its decline returns us to a historical norm. The "shared epistemi...
- The governance challenge is severe because personalization serves real human needs. People learn better with tailored information. The pathology is in personalization without a shared epistemic floor. Building that floor requires content provenance standards, public media, shared educational foun...
- *Require significant technological breakthroughs or specific policy choices, but cannot be dismissed.*

## Scenario #18: The Cognitive Enhancement Divide

- *Could be the greatest equalizer in history or the greatest divider. The difference is policy.*
- This has the highest governance dividend in the taxonomy after the intelligence explosion: 7 points. Universal cognitive enhancement would be the greatest equalizer in history. Restricted enhancement would be the greatest divider. Dario Amodei's "Machines of Loving Grace" (2024) envisions AI-driv...
- **Key tension:** The policy frameworks that will govern cognitive enhancement are being built now, in IP law and healthcare regulation, before the technology arrives.

## Scenario #19: The Democratic AI / Cognitive Bill of Rights

- ### 19. The Democratic AI / Cognitive Bill of Rights
- This is a prescription, not a prediction. AI capability treated as public infrastructure: universally accessible, publicly funded, democratically governed. Every citizen has access to equivalent AI tools regardless of income. AI enhances democratic participation through informed voting, transpare...
- The adversarial point: "democratic AI" as public infrastructure faces the same problems as other public goods. Government-run AI would be slower, less capable, and more bureaucratic than private alternatives. It would be subject to political interference. The history of public technology programs...
- This criticism has force. The response is that access to tools differs from democratic governance of the infrastructure. You can have cheap private AI and still face the power concentration problems other scenarios describe. The prescription is about governance, not delivery mechanism.

## Scenario #21: The Singleton

- One entity, whether a corporation, government, or AI itself, achieves such decisive advantage that it can establish permanent, unchallengeable global control. The mechanism need not be military force; it simply outthinks all adversaries in every domain simultaneously. Aschenbrenner's ["Situationa...
- The 9-point dividend means the institutional choices made now, which nations lead development, under what frameworks, with what accountability, determine the character of any future singleton. The argument for constitutionalizing AI governance before a singleton emerges is analogous to writing a ...

## Scenario #23: The Post-Scarcity Transition

- Post-scarcity requires the simultaneous success of several other scenarios: effective governance of AI power (#2), prevention of neo-feudalism (#15), democratic access (#19), and ecological resolution (#10). Post-scarcity is a political achievement institutions must create, never a gift technolog...
- This is a genuine philosophical challenge. The governed outcome (+5) represents the best version of this scenario, which may still involve significant positional competition even if material needs are met.

## Scenario #24: Mind Uploading / Digital Consciousness

- If achieved, every framework we use to organize society changes: death becomes optional, population becomes a policy variable, and law and morality must be rebuilt from their foundations. The governed outcome (+3) represents proactive preparation for these disruptions; the unmanaged outcome (-2) ...

## Scenario #26: AI Religion / Techno-Eschatology

- The singularity functions as secular eschatology: a transformative event that transcends the current order, promises immortality, and inaugurates a new age. The TESCREAL framework (Transhumanism, Extropianism, Singularitarianism, Cosmism, Rationalism, Effective Altruism, Longtermism) already oper...
- The practical danger: faith in AI salvation produces the same complacency as faith in divine salvation, waiting for deliverance rather than building solutions. If belief in the singularity substitutes for the hard political work of building institutions, it actively harms the governance responses...

## Scenario #28: The Transcendence / Omega Point

- Whether this is the best possible outcome or the worst depends on philosophical commitments irresolvable from this side. This is precisely why institutional design must happen now, while human values can still be embedded in the trajectory. If transcendence is possible, the values encoded in AI s...
- The adversarial point: this scenario is unfalsifiable and therefore has no policy implications. You cannot design governance for an outcome you cannot describe. The resources devoted to thinking about transcendence would be better spent on Tier 1 scenarios that are happening now.
- This is mostly right. The scenario is included for completeness because it features prominently in the discourse, and because the policy conclusion (build institutional safeguards now) is the same whether or not transcendence is possible.
- **Key tension:** Institutional design for the AI future must proceed without knowing whether that future includes entities that are recognizably human.

## Scenario #29: The Stasis / "Singularity That Wasn't"

- This is the most comforting scenario and therefore the most dangerous. If taken as grounds for complacency, it allows Tier 1 harms, labor displacement, power concentration, surveillance, epistemic collapse, to proceed without response. The argument for institutional design does not depend on the ...
- The adversarial point: if AI capabilities plateau, many of the more dramatic scenarios (extinction, singleton, transcendence) become moot, and the policy urgency around them was misallocated. Resources spent on alignment research for superintelligent systems would have been better spent on concre...
- This criticism has force. It reinforces rather than undermines the argument that institutional design for sub-catastrophic AI impacts is the most urgent priority.
- **Key tension:** Whether or not the singularity arrives, the institutional response to current AI capabilities is already overdue.

---

## Cross-Cutting Blueprint Themes

*To be developed. Initial observations from scenario analysis:*

1. **Distribution mechanisms:** Scenarios #1, #2, #15 all converge on the need for citizen ownership stakes, dividend structures, and VAT on automated production. Alaska Permanent Fund and Norway sovereign wealth fund cited as models.

2. **Content provenance infrastructure:** Scenarios #4, #5 require C2PA-style cryptographic verification. But #5 reveals that provenance alone is insufficient when the volume of participation overwhelms human-scale review. Identity verification and contribution gating are the complement.

3. **Cognitive sovereignty:** Scenarios #6, #17, #18 converge on education reform that distinguishes AI-assisted thinking from AI-replaced thinking. Finland model cited.

4. **Democratic oversight of AI power:** Scenarios #2, #8, #14, #19 require public governance structures for frontier AI. The "public utility" framing recurs.

5. **International coordination vs. arms race:** Scenarios #7, #11, #14, #20, #21 all depend on whether great power competition permits governance cooperation. The Biden-Xi nuclear AI statement and subsequent Chinese defection at REAIM illustrates the fragility.

6. **Alignment as prerequisite:** Scenarios #13, #20, #21, #27 all collapse without solved alignment. Technical safety research is the load-bearing dependency.

